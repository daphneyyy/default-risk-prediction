<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Scoring Risk of Default</title>
        <meta name="description"
            content="2024 UC San Diego Data Science Capstone Project, written by Section B18 Group 2.">
        <meta name="author" content="Jessica Guzman, Kuangyu Zou, Xuewen Yang, Haicheng Xu">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Tilt+Warp&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Red+Hat+Display:ital,wght@0,500;1,500&display=swap" rel="stylesheet">
        <link type="text/css" href="styles.css" rel="stylesheet">
        <link href="media/ucsd-icon.png" rel="icon">
    </head>
    <body>
        <header>
            <h1>Credit Score Alternative</h1>
            <h2>Scoring Risk of Default Using Banking Transaction Data</h2>
            <div class="authors">
                <p>By:
                    <a href="https://github.com/je-guz">Jessica
                        Guzman</a>,
                    <a href="https://github.com/Xu-Haicheng">Haicheng (Kevin)
                        Xu</a>,
                    <a href="https://github.com/daphneyyy">Xuewen (Daphne)
                        Yang</a>, and
                    <a href="https://github.com/KuangyuZou">Kuangyu (Connie)
                        Zou</a>.
                </p>
                <p>Mentors:
                    <a
                        href="https://www.linkedin.com/in/brian-duke-07666a8/">Brian
                        Duke (Prism Data, Inc.)</a> and
                    <a href="https://www.berkustun.com/">Berk Ustun (UCSD)</a>.
                </p>
            </div>
            <div class="links">
                <a href="https://github.com/daphneyyy/dsc-capstone-project"
                    class="resource-links" target="_blank" rel="noopener noreferrer">View Code</a>
                <a href="media/B18-2.pdf" class="resource-links" target="_blank" rel="noopener noreferrer">View
                    Poster</a>
                <a href="#" class="resource-links" target="_blank" rel="noopener noreferrer">View
                    Report</a>
            </div>
            <nav>
                <ul>
                    <li><a href="#abstract">Abstract</a></li>
                    <li><a href="#introduction">Introduction</a></li>
                    <li><a href="#methods">Methods</a></li>
                    <li><a href="#results">Results</a></li>
                    <li><a href="#discussion">Discussion</a></li>
                    <li><a href="#references">References</a></li>
                    <li><a href="#contact">Contacts</a></li>
                </ul>
            </nav>
        </header>
        <hr />
        <main>
            <section id="abstract">
                <h3>Abstract</h3>
                <p>In the current dynamic economic landscape, financial
                    institutions are increasingly harnessing the power of
                    machine learning to predict the risk of customer default.
                    The income, balance, and transaction category are three
                    important key factors correlated to the credit risk for each
                    customer. In this paper, we aim to develop a model that
                    combines all features related to these three aspects to
                    predict whether the customer will default their money to
                    banking. </p>
            </section>
            <section id="introduction">
                <h3>Introduction</h3>
                <p>Predicting the credit risk score for customers is crucial for
                    financial institutions to maintain a safe and organized
                    environment. When it comes to credit risk analysis in
                    particular, financial institutions tend to have access to
                    multitudes of important user data, but using it to
                    accurately and efficiently predict risk can become difficult
                    based on the data structure. In this project, we will focus
                    on combining customers' income, balance, and transaction
                    category information to create features that help the model
                    predict the default probabilities for each customer. For the
                    income features, we relate to income estimation work that we
                    did in Quarter 1 to estimate the outflow category spending
                    of income percentage. For the balance feature, we calculate
                    the cumulative balance sum and use the balance regression
                    coefficient as a threshold. For the transaction features, we
                    calculate the customer's percentage spent by both the inflow
                    and outflow categories. Additionally, we also define a
                    feature that correlates to the account type since different
                    account type has different inflow and outflow amounts per
                    customer.
                </p>
                <img src="media/Model_flow_chart.jpeg" alt="Model Flow Chart" />
            </section>
            <section id="methods">
                <h3>Methods</h3>
                <p>Our prediction model heavily depended on the features derived
                    from the datasets. This section outlines the methodologies
                    employed to generate these features, crucial for the
                    efficacy of our predictive modeling framework.
                </p>

                <img src="media/feature_breakdown_background.jpg"
                    alt="Feature Breakdown" />
                <div class="method">
                    <h4>Income Estimation</h4>
                    <p>One component we knew we wanted to include in order to 
                        assess risk of default was income. We believed people with 
                        steady income were more less likely to default, but since 
                        this measure is not monitored, we needed to estimate it. 
                        Our estimate depended on:</p>
                    <img src="media/Income_estimation_chart.jpeg" alt="Income Estimation Chart" />

                </div>
                <div class="method">
                    <h4>Feature Creation</h4>
                    <p>Nearly all our features can be categorized into four main types: balance, income, outflow, and inflow. Some features were derived from ratios between these categories, such as inflow-to-inflow category. This type of analysis aims to help explain trends in credit and debit proportions and their origins. Ratios not directly used were incorporated into a logistic regression model, where instead we utilized default probability as a feature. Another focus area was balance and its trends over time. Regression coefficients were calculated for balance and differences in balance, supplemented by moving averages to capture stable patterns. These features were designed to track changes in users' overall financial activity over extended periods. The final feature that does not fit into the aforementioned categories is account type count. 
                    </p>
                    <div class="dropdown-menu">
                        <details class="feature-detail">
                            <summary>Account Type Count</summary>
                            <p>We count the number of accounts for each account type users have. 
                            </p>
                        </details>
                        <details class="feature-detail">
                            <summary>Balance regression coefficient</summary>
                            <p>Coefficients representing linear trend across time for balance</p>
                        </details>
                        <details class="feature-detail">
                            <summary>Difference in balance regression coefficient</summary>
                            <p>Coefficients representing the linear trend of the difference in standardized balance across time for balance
                            </p>
                        </details>
                        <details class="feature-detail">
                            <summary>Simple moving average of standardized balance</summary>
                            <p style="font-family: 'Courier New', monospace; font-size: medium;">
                                SMA = Sum of average standardized balances in the window / (Number of data points in the window)
                            </p>
                            <p>We found all the SMA's calculated with a window size of two months for the last 7 months of data by account type.  
                            </p>
                                
                        </details>
                        <details class="feature-detail">
                            <summary>Exponential moving average of standardized balance</summary>
                            <p style="font-family: 'Courier New', monospace;">
                                EMA<sub>t</sub> = (&alpha; &times; Balance<sub>t</sub>) + ((1 - &alpha;) &times; EMA<sub>t-1</sub>)
                            </p>
                            <p> In this formula:</p>
                            <ul id="ema-formula">
                                <li><strong>Balance<sub>t</sub>:</strong> Standardized balance amount for current window.</li>
                                <li><strong>&alpha;:</strong> Factor for degree of exponential weighting given to recent observations. 
                                <li><strong>EMA<sub>t-1</sub>:</strong> Exponential Weighted Moving Average value from previous window</li>
                            </ul>
                            <p>We found all the EMA's calculated with a window size of two months for the most recent 7 months of data by account type. </p>
                        </details>
                        <details class="feature-detail">
                            <summary>Probability of Default by % Spent of Income by Category of Outflow</summary>
                            <p>We calculated the proportion spent of income by category of outflow, and then applied logistic regression to find the probability of default.
                            </p>
                        </details>
                        <details class="feature-detail">
                            <summary>Probability of Default by % Spent of Inflow by Category of Outflow</summary>
                            <p>We calculated the proportion spent of inflow by category of outflow, and then applied logistic regression to find the probability of default.
                            </p>
                        </details>
                        <details class="feature-detail">
                            <summary>% of Inflow by Inflow Category </summary>
                            <p>We calculated the proportion spent of inflow by category of inflow.</p>
                        </details>
                        <details class="feature-detail">
                            <summary>% of Inflow by Income Category </summary>
                            <p>We calculated the proportion spent of income by category of inflow.</p>
                        </details>
                        <details class="feature-detail">
                            <summary>% of Inflow by Outflow Category </summary>
                            <p>We calculated the proportion spent of outflow by category of inflow.</p>
                        </details>
                        <details class="feature-detail">
                            <summary>% of Outflow by Income Category </summary>
                            <p>We calculated the proportion spent of income by category of outflow.</p>
                        </details>
                    </div>
                </div>
                <div class="method">
                    <h4>Feature Selection and Models</h4>
                    <p>In refining our feature set for optimal model performance, 
                       we started with 132 features and streamlined them using exclusion 
                       criteria to remove bias-related features, such as those involving 
                       sensitive healthcare information. We assessed the importance of the 
                       remaining features differently for each model: logistic regression 
                       and SVM models were evaluated by their coefficients, while XGBoost 
                       used its feature importance function. Through cross-validation and 
                       iterative analysis, we identified and retained the most impactful 
                       features, enhancing the model's predictive capability.
                    </p>
                    <img src="media/feature_selection.jpg"
                        alt="Feature Selection" />

                    
                    <ul class="models">
                        <li>
                            <p>Logistic Regression</p>
                            <ul>
                                <li>The <a href="https://www.spiceworks.com/tech/artificial-intelligence/articles/what-is-logistic-regression/">Logistic Regression</a> serves as our baseline for predicting customer default outcomes, chosen for its aptness in binary classification tasks and flexibility across various types of independent variables. Feature selection is performed as described earlier, followed by model training and evaluation on a stratified train-test split to assess performance metrics  like accuracy and AUC score.</li>
                            </ul>
                        </li>
                        <li><p>Support Vector Machine</p>
                            <ul>
                                <li>We then explore the <a href="https://www.analyticsvidhya.com/blog/2021/10/support-vector-machinessvm-a-complete-guide-for-beginners/">Support Vector Machine</a> (SVM) model, recognized for its proficiency in high-dimensional spaces, such as text classification. The approach mirrors that of Logistic Regression, focusing on feature importance for model training and performance evaluation.</li>
                            </ul>
                        </li>
                        <li><p>XGBoost</p>
                            <ul>
                                <li>We focus on <a href="https://www.nvidia.com/en-us/glossary/xgboost/">XGBoost</a>, celebrated for its prowess with complex datasets and high accuracy across diverse data types. This makes it an excellent choice for our default prediction task. Our approach with XGBoost mirrors earlier models, starting with feature selection guided by the model's feature importance. We then train and evaluate XGBoost on the selected features, using metrics like accuracy, AUC score, and classification reports for performance assessment.</li>
                            </ul>
                        </li>
                    </ul>
                </div>
            </section>
            <section id="results">
                <h3>Results</h3>

                <table class="metrics">
                    <thead>
                        <tr>
                            <th>Metric</th>
                            <th>Definition</th>
                            <th>Formula</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Precision</td>
                            <td>Measures the percentage of predictions made by the model that are correct.</td>
                            <td>                                
                                <math display="inline" class="formulas">
                                    <mfrac>
                                        <mrow>
                                            <mi>True positives</mi>
                                        </mrow>
                                        <mrow>
                                            <mo>(</mo>
                                            <mi>True positives</mi>
                                            <mo>+</mo>
                                            <mi>False positives</mi>
                                            <mo>)</mo>
                                        </mrow>
                                    </mfrac>
                                </math>
                            </td>
                        </tr>
                        <tr>
                            <td>Recall</td>
                            <td>Measures the percentage of relevant data points that were correctly identified by the model.</td>
                            <td>
                                <math display="inline" class="formulas">
                                    <mfrac>
                                        <mrow>
                                            <mi>True positives</mi>
                                        </mrow>
                                        <mrow>
                                            <mo>(</mo>
                                            <mi>True positives</mi>
                                            <mo>+</mo>
                                            <mi>False negatives</mi>
                                            <mo>)</mo>
                                        </mrow>
                                    </mfrac>
                                </math>
                            </td>
                        </tr>
                        <tr>
                            <td>F1 Score</td>
                            <td>Harmonic mean of precision and recall.</td>
                            <td>
                                <math display="inline" class="formulas">
                                    <mfrac>
                                        <mrow>
                                            <mn>2</mn><mo>&times;</mo><mi>Precision</mi><mo>&times;</mo><mi>Recall</mi>
                                        </mrow>
                                        <mrow>
                                            <mi>Precision</mi><mo>+</mo><mi>Recall</mi>
                                        </mrow>
                                    </mfrac>
                                </math>
                            </td>
                        </tr>
                        <tr>
                            <td>Support</td>
                            <td>Number of actual occurrences of each class in the dataset.</td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td>Accuracy</td>
                            <td>Measures the number of correctly classified instances over the total number of instances.</td>
                            <td>
                                <math display="inline" class="formulas">
                                    <mfrac>
                                        <mrow>
                                            <mi>True positives</mi> <mo>+</mo> <mi>True negatives</mi>
                                        </mrow>
                                        <mrow>
                                            <mi>Total instances</mi>
                                        </mrow>
                                    </mfrac>
                                </math>
                            </td>
                        </tr>
                        <tr>
                            <td>Macro average</td>
                            <td>Average of metrics across all classes, treating each class equally.</td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td>Weighted average</td>
                            <td>Average of metrics across all classes, weighted by support.</td>
                            <td>N/A</td>
                        </tr>
                    </tbody>
                </table>

                <div class="model-performance">
                    <h4>Model Performance</h4>
                    <div class="model-result">
                        <h4>Logistic Regression</h4>
                        <div class="result-container">
                            <table>
                                <tr>
                                    <th></th>
                                    <th>precision</th>
                                    <th>recall</th>
                                    <th>f1-score</th>
                                    <th>support</th>
                                </tr>
                                <tr>
                                    <td>0</td>
                                    <td>0.82</td>
                                    <td>0.99</td>
                                    <td>0.90</td>
                                    <td>798</td>
                                </tr>
                                <tr>
                                    <td>1</td>
                                    <td>0.63</td>
                                    <td>0.09</td>
                                    <td>0.16</td>
                                    <td>185</td>
                                </tr>
                                <tr>
                                    <td>accuracy</td>
                                    <td></td>
                                    <td></td>
                                    <td>0.82</td>
                                    <td>983</td>
                                </tr>
                                <tr>
                                    <td>macro avg</td>
                                    <td>0.73</td>
                                    <td>0.54</td>
                                    <td>0.53</td>
                                    <td>983</td>
                                </tr>
                                <tr>
                                    <td>weighted avg</td>
                                    <td>0.79</td>
                                    <td>0.82</td>
                                    <td>0.76</td>
                                    <td>983</td>
                                </tr>
                            </table>
                            <img src="media/roc_curve_figure_lr.png"
                                alt="ROC Curve for Logistic Regression" />
                        </div>
                    </div>
                    <div class="model-result">
                        <h4>Support Vector Machine</h4>
                        <div class="result-container">
                            <table>
                                <tr>
                                    <th></th>
                                    <th>precision</th>
                                    <th>recall</th>
                                    <th>f1-score</th>
                                    <th>support</th>
                                </tr>
                                <tr>
                                    <td>0</td>
                                    <td>0.88</td>
                                    <td>0.93</td>
                                    <td>0.90</td>
                                    <td>798</td>
                                </tr>
                                <tr>
                                    <td>1</td>
                                    <td>0.00</td>
                                    <td>0.00</td>
                                    <td>0.00</td>
                                    <td>185</td>
                                </tr>
                                <tr>
                                    <td>accuracy</td>
                                    <td></td>
                                    <td></td>
                                    <td>0.81</td>
                                    <td>983</td>
                                </tr>
                                <tr>
                                    <td>macro avg</td>
                                    <td>0.41</td>
                                    <td>0.50</td>
                                    <td>0.45</td>
                                    <td>983</td>
                                </tr>
                                <tr>
                                    <td>weighted avg</td>
                                    <td>0.66</td>
                                    <td>0.81</td>
                                    <td>0.73</td>
                                    <td>983</td>
                                </tr>
                            </table>
                            <img src="media/roc_curve_figure_svm.png"
                                alt="ROC Curve for SVM" />
                        </div>
                    </div>
                    <div class="model-result">
                        <h4>XGBoost</h4>
                        <div class="result-container">
                            <table>
                                <tr>
                                    <th></th>
                                    <th>precision</th>
                                    <th>recall</th>
                                    <th>f1-score</th>
                                    <th>support</th>
                                </tr>
                                <tr>
                                    <td>0</td>
                                    <td>0.81</td>
                                    <td>1.00</td>
                                    <td>0.90</td>
                                    <td>798</td>
                                </tr>
                                <tr>
                                    <td>1</td>
                                    <td>0.59</td>
                                    <td>0.44</td>
                                    <td>0.50</td>
                                    <td>185</td>
                                </tr>
                                <tr>
                                    <td>accuracy</td>
                                    <td></td>
                                    <td></td>
                                    <td>0.84</td>
                                    <td>983</td>
                                </tr>
                                <tr>
                                    <td>macro avg</td>
                                    <td>0.73</td>
                                    <td>0.68</td>
                                    <td>0.70</td>
                                    <td>983</td>
                                </tr>
                                <tr>
                                    <td>weighted avg</td>
                                    <td>0.82</td>
                                    <td>0.84</td>
                                    <td>0.83</td>
                                    <td>983</td>
                                </tr>
                            </table>
                            <img src="media/roc_curve_figure_xgb.png"
                                alt="ROC Curve for XGBoost" />
                        </div>
                    </div>
                </div>
                <p>Based on the results of our three models, all the accuracy
                    scores of our models reached 80 percent or higher,
                    indicating the models are performing well across both
                    classes. This means that for a given set of data, our models
                    can correctly identify whether a customer will default or
                    not 80 percent of time. Additionally, based on the AUC
                    score, the xgboost model has the best result. An AUC score,
                    or Area Under the Receiver Operating Characteristic (ROC)
                    Curve, of 0.87 indicates a high level of model performance
                    in distinguishing between the positive class (e.g.,
                    customers who will default) and the negative class (e.g.,
                    customers who will not default). So there is an 87 percent
                    chance that the model will be able to distinguish between a
                    randomly chosen positive instance and a randomly chosen
                    negative instance. This is considered to be a very good
                    performance, indicating that the model has a high likelihood
                    of correctly classifying customers who will default on loans
                    versus those who will not.
                </p>
            </section>
            
            <section id="Model Output">
                <h3>Model Output</h3>
                <ul class="models">
                        <li>
                            <p>Default Probability</p>
                            <ul>
                                <li>We assign each user a probability of default score from 0 to 1. </li>
                            </ul>
                        </li>
                        <li>
                            <p>Reason Code</p>
                            <ul>
                                <li>We can also provide the top 3 reasons why any given candidate
                                    might raise concerns for defaulting based on the model
                                <img src="media/most_common_reasons.png"
                                alt="ROC Curve for XGBoost" />
                                </li>
                            </ul>
                        </li>
                    </ul>
            </section>
            
            <section id="discussion">
                <h3>Discussion</h3>
                <p>The model's performance in predicting class 1 is suboptimal, with precision, recall, and F1-score values of 0.59, 0.44, and 0.5, respectively. This limitation stems primarily from two factors: the composition of the data and the inherent characteristics of the model. In our training dataset, more than 80 percent of customers belong to class 0 (non-defaulters), while less than 20 percent are in class 1 (defaulters). Consequently, the model tends to prioritize optimizing precision and recall for class 0 at the expense of class 1.
                </p>
            </section>
            <section id="contribution">
                <h3>Contributions Beyond</h3>
                <p>By leveraging transaction data from user accounts, we broaden the scope of potential borrowers we can cater to, all while striving for the most accurate distinction between sound and risky loans. Significantly, we also try to adhere to strict ethical standards, refraining from utilizing features that could lead to discrimination against protected classes. We also attempted to avoid indirect discrimination by normalizing and analyzing users' transaction histories against themselves. In summary, our model expands access to the market ethically, accommodating a broader range of users, while concurrently optimizing loan quality by emphasizing good loans and mitigating the risk of bad ones. Overall, our model promotes financial justice and ethical decision-making while guaranteeing inclusion without sacrificing the integrity of our lending operations.
                </p>
            </section>
            <a href="#" aria-label="Go to top of the page" id="top-btn">Go To Top &uarr;</a>
        </main>
        <footer>
            <div class="footer-container">
                <h3 id="contact">Contacts: </h3>
                <div class="contact">
                    <div class="contact-links">
                        <p>Xuewen Yang</p>
                        <a
                            href="mailto:xuy001@ucsd.edu"><i>xuy001@ucsd.edu</i></a>
                    </div>
                    <div class="contact-links">
                        <p>Haicheng Xu</p>
                        <a
                            href="mailto:hax004@ucsd.edu"><i>hax004@ucsd.edu</i></a>
                    </div>
                    <div class="contact-links">
                        <p>Jessica Guzman</p>
                        <a
                            href="mailto:jeguzman@ucsd.edu"><i>jeguzman@ucsd.edu</i></a>
                    </div>
                    <div class="contact-links">
                        <p>Kuangyu Zou</p>
                        <a href="mailto:kzou@ucsd.edu"><i>kzou@ucsd.edu</i></a>
                    </div>
                </div>
                <p>This page was generated by <a
                        href="https://pages.github.com/" target="_blank">GitHub
                        Pages</a></p>
                <p>&copy; 2024 Xuewen, Kuangyu, Jessica, and Haicheng. All
                    rights reserved.</p>
            </div>
        </footer>
    </body>
</html>
